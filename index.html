<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Brian Wheatman</title>

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.7.0/jquery.min.js"></script>

    <!-- Bootstrap Core CSS -->
    <link href="css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom CSS -->
    <link href="css/grayscale.css" rel="stylesheet">

    <!-- Custom Fonts -->
    <link href="font-awesome/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link href="https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic" rel="stylesheet"
        type="text/css">
    <link href="https://fonts.googleapis.com/css?family=Montserrat:400,700" rel="stylesheet" type="text/css">



    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-2HJB06VQ04"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());

        gtag('config', 'G-2HJB06VQ04');
    </script>



    <style>
        .filterDiv {
            display: none;
        }

        .fshow {
            display: block;
        }

        /* Style the buttons */
        .fbtn {
            border: none;
            outline: none;
            padding: 12px 16px;
            background-color: #595454;
            cursor: pointer;
        }

        .fbtn:hover {
            background-color: #a8a0a0;
        }

        .fbtn.clicked {
            background-color: #c9c2c2;
            color: rgb(5, 4, 4);
        }
    </style>


    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->



</head>

<body id="page-top" data-spy="scroll" data-target=".navbar-fixed-top">
    <script src="js/bootstrap.js"></script>


    <!-- Navigation -->
    <nav class="navbar navbar-custom navbar-fixed-top" role="navigation">
        <div class="container">
            <div class="navbar-header">
                <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar"
                    data-bs-target="#navbar" aria-expanded="false" aria-controls="navbar">
                    <em class="fa fa-bars"></em>
                </button>
                <a class="navbar-brand page-scroll" href="#page-top">
                    <em class="fa fa-user animated"></em> <span class="light">Brian<span> Wheatman
                </a>
            </div>

            <!-- Collect the nav links, forms, and other content for toggling -->
            <div id="navbar" class="navbar-collapse collapse">
                <ul class="nav navbar-nav navbar-right">
                    <!-- Hidden li included to remove active class from about link when scrolled up past about section -->
                    <li>
                        <a class="page-scroll" href="#about">About</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#Publications">Publications</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#Invited Talks">Invited Talks</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#Current">Current Work</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#education">Education</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#teaching">Teaching</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#professional">Professional Experience</a>
                    </li>
                    <li>
                        <a href="./cv.pdf">CV</a>
                    </li>

                </ul>
            </div>
            <!-- /.navbar-collapse -->
        </div>
        <!-- /.container -->
    </nav>

    <!-- Intro Header -->
    <header class=" intro">
        <div class="intro-body">
            <div class="container">
                <div class="row">
                    <div class="col-md-8 col-md-offset-2">
                        <h1 class="brand-heading">Brian Wheatman</h1>
                        <p class="intro-text">A PhD student in Computer Science.</p>
                        <a href="#about" class="btn btn-circle page-scroll">
                            <em class="fa fa-angle-double-down animated"></em>
                        </a>
                    </div>
                </div>
            </div>
        </div>
    </header>

    <!-- About Section -->
    <section id="about" class="container content-section text-center">
        <h2>About Brian</h2>
        <ul class="text-left" style="display:inline-block;vertical-align:middle;">
            <p>
                I am a PhD Student in Computer Science at Johns Hopkins University.
                I am fortunate to be advised by <a href="https://www.cs.jhu.edu/faculty/randal-burns/">Randal
                    Burns</a>.
            <p>
                My research interests include:
            <ul class="text-left" style="display:inline-block;vertical-align:middle;">
                <li> Graph Analytics</li>
                <li> Parallel Data Structures and Algorithms</li>
                <li> Big Data and Distributed Systems </li>
                <li> Performance Engineering</li>

            </ul>
            </p>


            <p>
                For more information on my work, go to <a class="page-scroll" href="#Publications">Publications</a> or
                <a class="page-scroll" href="#Current">Current Work</a>.
            </p>

            <p>
                For a list of papers and presentations, see <a
                    href="https://scholar.google.com/citations?user=vP2to0MAAAAJ&hl=en&oi=ao">
                    Google
                    Scholar</a>.
            </p>
            <p>
                I also enjoy rock climbing, hiking, and traveling.
            </p>
        </ul>
    </section>

    <section id="Publications" class="container content-section text-center">
        <h1><u>Publications</u></h1>
        <hr>
        <div id="myBtnContainer">
            <button class="fbtn clicked" onclick="filterSelection('all')"> Show all</button>
            <button class="fbtn" onclick="filterSelection('DS')"> Data Structures</button>
            <button class="fbtn" onclick="filterSelection('graphs')"> Graphs</button>
            <button class="fbtn" onclick="filterSelection('PMA')"> Packed Memory Arrays</button>
            <button class="fbtn" onclick="filterSelection('others')"> Others</button>
        </div>

        
        <section id="post" class="container text-center">
            <div class="row filterDiv DS graphs ">
                <hr>
                <div class="col-lg-12 col-lg-offset-0">
                    <h2>BYO: A Unified Framework for Benchmarking Large-Scale
                        Graph Containers</h2>
                    <p><b>Brian Wheatman</b>, Xiaojun Dong, Zheqi Shen,  <a href = "https://www.cs.umd.edu/~laxman/">Laxman Dhulipala</a>, <a
                            href="https://research.google/people/jakub-%C5%82%C4%85cki/">Jakub Łącki</a>, <a href="https://prashantpandey.github.io/">Prashant Pandey</a>,
                        and <a href="https://itshelenxu.github.io/">Helen Xu</a></p>
                    <ul class="text-left">
                        <details>
                            <summary>
                                <strong>Abstract</strong>
                            </summary>
                            <p>
                                A fundamental building block in any graph algorithm is a graph container – a data
                                structure
                                used to represent the graph. Ideally, a graph container enables efficient access to the
                                underlying graph and supports updating the graph efficiently. In this paper, we conduct
                                an
                                extensive empirical evaluation of graph containers designed to support running
                                algorithms on
                                large graphs. To our knowledge, this is the first apples-to-apples comparison of graph
                                containers rather than overall systems, which include confounding factors such as
                                differences in algorithm implementations and infrastructure.
                            </p>
                            <p>
                                We measure the running time of 10 highly-optimized algorithms across over 20+ different
                                containers and 10 graphs. Somewhat surprisingly, we find that the average algorithm
                                running
                                time does not differ much across containers, especially those that support dynamic
                                updates.
                                Specifically, a simple container based on an off-the-shelf B-tree is only 1.22× slower
                                on
                                average than a highly optimized static one. Moreover, we observe that simplifying a
                                graph-container Application Programming Interface (API) to only a few simple functions
                                incurs a mere 1.16× slowdown compared to a complete API. Finally, we also measure
                                batch-insert throughput in dynamic-graph containers for a full picture of their
                                performance.
                            </p>
                            <p>
                                To perform the benchmarks, we introduce BYO, a unified framework that standardizes
                                evaluations of graph-algorithm performance across different graph containers. BYO
                                extends
                                the Graph Based Benchmark Suite (Dhulipala et al. 18), a state-of-the-art graph
                                algorithm
                                benchmark, to easily plug into different dynamic graph containers and enable fair
                                comparisons between them on a large suite of graph algorithms. While several graph
                                algorithm
                                benchmarks have been developed to date, to the best of our knowledge, BYO is the first
                                system designed to benchmark graph containers.
                            </p>
                        </details>
                        <br>
                        <ul class="text-left" style="display:inline-block;vertical-align:middle;padding-left:0">

                            <li>To be presented at <a href="https://vldb.org/2024/">VLDB 2024</a>
                            </li>
                            <li>
                                The code can be found on github <a
                                    href="https://github.com/wheatman/BYO">https://github.com/wheatman/BYO</a>
                            </li>

                        </ul>
                    </ul>
                </div>
            </div>

        </section>

        
        <section id="post" class="container text-center">
            <div class="row filterDiv others">
                <hr>
                <div class="col-lg-12 col-lg-offset-0">
                    <h2><a href="https://tcpp.cs.gsu.edu/curriculum/sites/default/files/EduPar-09-EduPar___SpeedCode.cameraready.pdf">Speedcode: Software Performance Engineering
                        Education via the Coding of Didactic Exercises</a></h2>
                    <p><a href="http://tfk.mit.edu/">Tim Kaler</a>, <a href = "https://people.csail.mit.edu/xchen/">Xuhao Chen</a>, <b>Brian Wheatman</b>, <a href = "https://pmg.csail.mit.edu/~dcurtis/">Dorothy Curtis</a>, Bruce Hoppe, <a href = "https://neboat.mit.edu/">Tao B. Schardl</a>, and <a href = "https://people.csail.mit.edu/cel/">Charles E. Leiserson</a></p>
                    <ul class="text-left">
                        <details>
                            <summary>
                                <strong>Abstract</strong>
                            </summary>
                            <p>
                                This paper introduces Speedcode, an online programming platform that aims to improve the accessibility of software performance-engineering education. At its core, Speedcode provides a platform that lets users gain hands-on experience in software performance engineering and parallel programming by completing short programming exercises.

                            </p>
                            <p>
                                Speedcode challenges users to develop fast multicore solutions for short programming problems and evaluates their code’s performance and scalability in a quiesced cloud environment. Speedcode supports parallel programming using OpenCilk, a task-parallel computing platform that is open-source and easy to program, teach and use for research.

                            </p>
                            <p>
                                Speedcode aims to reduce barriers to learning and teaching software performance engineering. It allows users to run and evaluate their code on modern multicore machines from their own computer without installing any software. This provides users an easy introduction to the topic, and enables teachers to more easily incorporate lessons on software performance engineering into their courses without incurring the onerous overhead of needing to setup computing environments for their students.
                            </p>
                        </details>
                        <br>
                        <ul class="text-left" style="display:inline-block;vertical-align:middle;padding-left:0">

                            <li>Presented at <a href="https://tcpp.cs.gsu.edu/curriculum/?q=edupar24">EduPar-24</a>, in conjuction with <a href = "https://www.ipdps.org/">IPDPS 2024</a>
                            </li>

                        </ul>
                    </ul>
                </div>
            </div>

        </section>

        <section id="post" class="container text-center">
            <div class="row filterDiv DS graphs PMA">
                <hr>
                <div class="col-lg-12 col-lg-offset-0">
                    <h2><a href="https://dl.acm.org/doi/10.1145/3627535.3638492">CPMA: An Efficient
                            Batch-Parallel Compressed Set Without Pointers</a></h2>
                    <p><b>Brian Wheatman</b>, <a href="https://randalburns.github.io/">Randal Burns</a>, <a
                            href="https://people.eecs.berkeley.edu/~aydin/">Aydın Buluç</a>,
                        and <a href="https://itshelenxu.github.io/">Helen Xu</a></p>
                    <ul class="text-left">
                        <details>
                            <summary>
                                <strong>Abstract</strong>
                            </summary>
                            <p>
                                This paper introduces the batch-parallel Compressed Packed Memory Array (CPMA), a
                                compressed dynamic ordered batch-parallel set data structure based on the Packed Memory
                                Array (PMA). Traditionally, batch-parallel sets are built on pointer-based data
                                structures such as trees because pointer-based structures enable fast parallel unions
                                via pointer manipulation. When compared to cache-optimized trees, PMAs were slower to
                                update but faster to scan.

                            </p>
                            <p>
                                The batch-parallel CPMA overcomes this tradeoff between updates and scans by optimizing
                                for cache-friendliness. On average, the CPMA achieves 3× faster batch-insert throughput
                                and 4× faster range-query throughput compared to compressed PaC-trees, a
                                state-of-the-art batch-parallel set library based on cache-optimized trees.

                            </p>
                            <p>
                                We further evaluate the CPMA compared to compressed PaC-trees and Aspen, a
                                state-of-the-art system, on a realworld application of dynamic-graph processing. The
                                CPMA is on average 1.2× faster on a suite of graph algorithms and 2× faster on batch
                                inserts when compared with compressed PaC-trees. Furthermore, the CPMA is on average
                                1.3× faster on graph algorithms and 2× faster on batch inserts compared to Aspen.
                            </p>
                        </details>
                        <br>
                        <ul class="text-left" style="display:inline-block;vertical-align:middle;padding-left:0">

                            <li>Presented at <a href="https://conf.researchr.org/home/PPoPP-2024">PPoPP
                                    2024</a>, where it won Best Artifact Award
                            </li>
                            <li>
                                The code can be found on github <a
                                    href="https://github.com/wheatman/Packed-Memory-Array">https://github.com/wheatman/Packed-Memory-Array</a>
                            </li>

                        </ul>
                    </ul>
                </div>
            </div>

        </section>

        <section id="post" class="container text-center">
            <div class="row  filterDiv DS">
                <hr>
                <div class="col-lg-12 col-lg-offset-0">
                    <h2><a href="https://dl.acm.org/doi/10.14778/3611479.3611502">BP-tree:
                            Overcoming the Point-Range Operation Tradeoff for In-Memory B-trees</a></h2>
                    <p><a href="https://itshelenxu.github.io/">Helen Xu</a>, Amanda Li, <b>Brian Wheatman</b>, Manoj
                        Marneni, and <a href="https://prashantpandey.github.io/">Prashant Pandey</a></p>
                    <ul class="text-left">
                        <details>
                            <summary>
                                <strong>Abstract</strong>
                            </summary>
                            <p>
                                B-trees are the go-to data structure for in-memory indexes in
                                databases and storage systems. B-trees support both point operations (i.e., inserts and
                                finds) and range operations (i.e., iterators and
                                maps). However, there is an inherent tradeoff between point and
                                range operations since the optimal node size for point operations
                                is much smaller than the optimal node size for range operations.
                                Existing implementations use a relatively small node size to achieve
                                fast point operations at the cost of range operation throughput.
                            </p>
                            <p>
                                We present the BP-tree, a variant of the B-tree, that overcomes
                                the decades-old point-range operation tradeoff in traditional B-trees.
                                In the BP-tree, the leaf nodes are much larger in size than the internal nodes to
                                support faster range scans. To avoid any slowdown in
                                point operations due to large leaf nodes, we introduce a new insertoptimized array
                                called the buffered partitioned array (BPA) to
                                efficiently organize data in leaf nodes. The BPA supports fast insertions by delaying
                                ordering the keys in the array. This results in much
                                faster range operations and faster point operations at the same time
                                in the BP-tree.

                            </p>
                            <p>
                                Our experiments show that on 48 hyperthreads, on workloads
                                generated from the Yahoo! Cloud Serving Benchmark (YCSB), the
                                BP-tree supports similar or faster point operation throughput (between .94×−1.2× faster)
                                compared to Masstree and OpenBw-tree,
                                two state-of-the-art in-memory key-value (KV) stores. On a YCSB
                                workload with short scans, the BP-tree is about 7.4× faster than
                                Masstree and 1.6× faster than OpenBw-tree. Furthermore, we extend the YCSB to add large
                                range workloads, commonly found in
                                database applications, and show that the BP-tree is 30× faster than
                                Masstree and 2.5× faster than OpenBw-tree.
                            </p>
                            <p>
                                We also provide a reference implementation for a concurrent B+
                                -
                                tree and find that the BP-tree supports faster (between 1.03×−1.2×
                                faster) point operations when compared to the best-case configuration for B+
                                -trees for point operations while supporting similar
                                performance (about .95×as fast) on short range operations and faster
                                (about 1.3× faster) long range operations
                            </p>
                        </details>
                        <br>
                        <ul class="text-left" style="display:inline-block;vertical-align:middle;padding-left:0">

                            <li>Presented at <a href="https://vldb.org/2023/">VLDB 2023</a>
                            </li>
                            <li>Presented as a Poster at <a href="https://ucrparlay.github.io/hopc24/">Highlights
                                of Parallel Computing 2024</a> at SPAA 2024
                        </li>
                            <li>
                                For a video of the talk, see <a href="https://youtu.be/d5lcKfhdiHY">here</a>
                            </li>
                            <li>
                                The code can be found on github <a
                                    href="https://github.com/wheatman/BP-Tree">https://github.com/wheatman/BP-Tree</a>
                            </li>

                        </ul>
                    </ul>
                </div>
            </div>

        </section>

        <section id="post" class="container text-center">
            <div class="row  filterDiv DS PMA">
                <hr>
                <div class="col-lg-12 col-lg-offset-0">
                    <h2><a href="https://epubs.siam.org/doi/abs/10.1137/1.9781611977561.ch13">Optimizing
                            Search Layouts in Packed Memory Arrays</a></h2>
                    <p><b>Brian Wheatman</b>, <a href="https://randalburns.github.io/">Randal Burns</a>, <a
                            href="https://people.eecs.berkeley.edu/~aydin/">Aydın Buluç</a>,
                        and <a href="https://itshelenxu.github.io/">Helen Xu</a></p>
                    <ul class="text-left">
                        <details>
                            <summary>
                                <strong>Abstract</strong>
                            </summary>
                            <p>
                                This paper introduces Search-optimized Packed Memory Arrays (SPMAs), a collection of
                                data structures based on Packed Memory Arrays (PMAs) that address suboptimal search via
                                cache-optimized search layouts. Traditionally, PMAs and B-trees have tradeoffs between
                                searches/inserts and scans: B-trees were faster for searches and inserts, while PMAs
                                were faster for scans.
                            </p>
                            <p>
                                Our empirical evaluation shows that SPMAs overcome this tradeoff for unsorted input
                                distributions: on average, SPMAs are faster than B+-trees (a variant of B-trees
                                optimized for scans) on all major operations. We generated datasets and search/insert
                                workloads from the Yahoo! Cloud Serving Benchmark (YCSB) and found that SPMAs are about
                                2× faster than B+-trees regardless of the ratio of searches to inserts. On uni form
                                random inputs, SPMAs are on average between 1.3 × −2.3× faster than B+-trees on all
                                operations. Finally, we vary the amount of sortedness in the inputs to stress the
                                worst-case insert distribution in the PMA. We find that the worst-case B+-tree insertion
                                throughput is about 1.5× faster than the worst-case PMA insertion throughput. However,
                                the worst-case input for the PMA is sorted and highly unlikely to appear naturally in
                                practice. The SPMAs maintain higher insertion throughput than the B+-tree when the input
                                is up to 25% sorted.
                            </p>
                        </details>
                        <br>
                        <ul class="text-left" style="display:inline-block;vertical-align:middle;padding-left:0">

                            <li>Presented at <a href="https://www.siam.org/conferences/cm/conference/alenex23">SIAM
                                    ALENEX 2023</a>
                            </li>
                            <li>
                                The code can be found on github <a
                                    href="https://github.com/wheatman/Packed-Memory-Array">https://github.com/wheatman/Packed-Memory-Array</a>
                            </li>

                        </ul>
                    </ul>
                </div>
            </div>
        </section>


        <section id="post" class="container text-center">
            <div class="row  filterDiv DS graphs">
                <hr>
                <div class="col-lg-12 col-lg-offset-0">
                    <h2><a href="https://ieeexplore.ieee.org/abstract/document/9671836">Streaming
                            Sparse Graphs using Efficient Dynamic Sets</a></h2>
                    <p><b>Brian Wheatman</b> and <a href="https://randalburns.github.io/">Randal Burns</a></p>
                    <ul class="text-left">
                        <details>
                            <summary>
                                <strong>Abstract</strong>
                            </summary>
                            <p>
                                We present the SSTGraph framework for the storage and analysis of dynamic graphs.
                                Its performance matches or exceeds state-of-the-art static graph engines and supports
                                streaming
                                updates. SSTGraph builds on top of the tinyset parallel, dynamic set data structure.
                                Tinyset implements set membership in a shallow hierarchy of sorted packed memory arrays
                                to
                                achieve logarithmic time access and updates, and it scans in optimal linear time.
                                Tinyset uses space comparable to that of systems that use data compression while
                                avoiding compression's computation and serialization overhead.
                            </p>
                            <p>
                                SSTGraph outperforms other streaming, dynamic graph engines on a suite of four graph
                                algorithms.
                                Our evaluation includes a comparison with the Aspen streaming graph system. SSTGraph
                                reduces
                                runtime by 40% on average, updates are 2x-5x faster on batch sizes up to 10 million, and
                                graphs
                                are smaller.
                                The partitioned data structure scales well and runs on billion edge graphs in just 15 GB
                                of
                                memory.
                            </p>
                        </details>
                        <br>
                        <ul class="text-left" style="display:inline-block;vertical-align:middle;padding-left:0">

                            <li>Presented at <a href="https://bigdataieee.org/BigData2021/index.html">IEEE
                                    BigData 2021</a>
                            </li>
                            <li>Presented as a Poster at <a href="https://ucrparlay.github.io/hopc23/cfp/">Highlights
                                    of Parallel Computing 2023</a> at SPAA 2023
                            </li>
                            <li>
                                For a video of the talk, see <a href="https://youtu.be/02kgqE8T0qQ">here</a>
                            </li>
                            <li>
                                The code can be found on github <a
                                    href="https://github.com/wheatman/SSTGraph">https://github.com/wheatman/SSTGraph</a>
                            </li>

                        </ul>
                    </ul>
                </div>
            </div>
        </section>

        <section id="post" class="container text-center">
            <div class="row  filterDiv DS graphs">
                <hr>
                <div class="col-lg-12 col-lg-offset-0">
                    <h2><a href="https://dl.acm.org/doi/10.1145/3448016.3457313">Terrace:
                            A
                            Hierarchical Graph Container for
                            Skewed Dynamic Graphs</a></h2>
                    <p><a href="https://prashantpandey.github.io/">Prashant Pandey</a>, <b>Brian Wheatman</b>, <a
                            href="https://itshelenxu.github.io/">Helen Xu</a>, and <a
                            href="https://people.eecs.berkeley.edu/~aydin/">Aydın Buluç</a></p>
                    <ul class="text-left">
                        <details>
                            <summary>
                                <strong>Abstract</strong>
                            </summary>
                            <p> Various applications model problems as streaming graphs, which need to quickly
                                apply a stream of updates and run algorithms on the updated graph. Furthermore,
                                many dynamic real-world graphs, such as social networks, follow a skewed
                                distribution of vertex degrees, where there are a few high-degree vertices and
                                many low-degree vertices.
                            </p>
                            <p>
                                Existing static graph-processing systems optimized for graph skewness achieve
                                high performance and low space usage by preprocessing a cache-efficient graph
                                partitioning based on vertex degree. In the streaming setting, the whole graph
                                is not available upfront, however, so finding an optimal partitioning is not
                                feasible in the presence of updates. As a result, existing streaming
                                graph-processing systems take a "one-size-fits-all" approach, leaving
                                performance on the table.
                            </p>
                            <p>
                                We present Terrace, a system for streaming graphs that uses a hierarchical data
                                structure design to store a vertex's neighbors in different data structures
                                depending on the degree of the vertex. This multi-level structure enables
                                Terrace to dynamically partition vertices based on their degrees and adapt to
                                skewness in the underlying graph.
                            </p>
                            <p>
                                Our experiments show that Terrace supports faster batch insertions for batch
                                sizes up to 1M when compared to Aspen, a state-of-the-art graph streaming
                                system.

                                On graph query algorithms, Terrace is between 1.7x--2.6x faster
                                than Aspen and between 0.5x--1.3x as fast as Ligra, a
                                state-of-the-art static graph-processing system.
                            </p>
                        </details>
                        <br>
                        <ul class="text-left" style="display:inline-block;vertical-align:middle;padding-left:0">

                            <li>
                                Presented at <a href="https://2021.sigmod.org/index.shtml">SIGMOD
                                    2021</a>
                            </li>
                            <li>
                                For a video of the talk, see <a
                                    href="https://www.youtube.com/watch?v=O_affhnP_5Q&list=PL3xUNnH4TdbsfndCMn02BqAAgGB0z7cwq">here</a>
                            </li>
                            <li>
                                The code can be found on github <a
                                    href="https://github.com/PASSIONLab/terrace">https://github.com/PASSIONLab/terrace</a>
                            </li>
                        </ul>
                    </ul>
                </div>
            </div>
        </section>


        <!-- Post Section -->
        <section id="post" class="container text-center">
            <div class="row  filterDiv others">
                <hr>
                <div class="col-lg-12 col-lg-offset-0">
                    <h2><a href="https://ieeexplore.ieee.org/abstract/document/9502465">RADICS:
                            Runtime Assurance of Distributed Intelligent Control Systems</a></h2>
                    <p><b>Brian Wheatman</b>, Jerry Chen, <a href="https://ep.jhu.edu/faculty/tamim-sookoor/">Tamim
                            Sookoor</a>, and <a href="https://www.cs.jhu.edu/~yairamir/">Yair Amir</a></p>
                    <ul class="text-left">
                        <details>
                            <summary>
                                <strong>Abstract</strong>
                            </summary>
                            <p> We describe RADICS: Runtime Assurance of Distributed Intelligent Control Systems, which
                                combines
                                a Simplex-based, black-box monitor with a white-box monitor to ensure correct behavior
                                and
                                good
                                performance of AI systems. The black-box monitor allows the system to detect when the AI
                                controller is on a failing trajectory and use a provably safe, but less performant
                                algorithm, to
                                right the system. The white-box monitor predicts when the AI controller will be put on
                                such
                                a
                                trajectory before it happens and helps maximize the performance of the overall system.
                                We
                                describe the overall approach in detail and implement a simple version of it on a case
                                study
                                into controlling the lights in a small traffic grid.
                            </p>
                        </details>
                        <br>
                        <ul class="text-left" style="display:inline-block;vertical-align:middle;padding-left:0">
                            <li>Presented at <a href="https://dependablesecureml.github.io/index.html">DSML
                                    2021</a></li>
                            <li>For a video of the talk, see <a
                                    href="https://www.youtube.com/watch?v=Tc44H6ryxqc">here</a>
                            </li>
                            <li>For more information see <a
                                    href="http://www.dsn.jhu.edu/radics/">http://www.dsn.jhu.edu/radics/</a>
                            </li>
                        </ul>

                    </ul>
                </div>
            </div>
        </section>

        <section id="post" class="container text-center">
            <div class="row  filterDiv DS graphs PMA">
                <hr>
                <div class="col-lg-12 col-lg-offset-0">
                    <h2><a href="https://epubs.siam.org/doi/abs/10.1137/1.9781611976472.3">A
                            Parallel Packed Memory Array to
                            Store Dynamic Graphs</a></h2>
                    <p><b>Brian Wheatman</b> and <a href="https://itshelenxu.github.io/">Helen Xu</a></p>
                    <ul class="text-left">
                        <details>
                            <summary>
                                <strong>Abstract</strong>
                            </summary>
                            <p>
                                The ideal data structure for storing dynamic graphs would support fast updates as well
                                as
                                fast
                                range
                                queries which underlie graph traversals such as breadth-first search. The Packed Memory
                                Array
                                (PMA)
                                seems like a good candidate for this setting because it supports fast updates as well as
                                cache-efficient range queries. Concurrently updating a PMA raises challenges, however,
                                because
                                an
                                update may require rewriting the entire structure.
                            </p>
                            <p>
                                This paper introduces a parallel PMA with intra- and inter-operation parallelism and
                                deadlock-free
                                polylogarithmicspan operations. Our main observation is that the PMA is well-suited to
                                concurrent
                                updates despite occasionally requiring a rewrite of the entire structure because 1) most
                                of
                                the
                                updates only write to a small part of the structure and 2) the worst case is highly
                                parallel
                                and
                                cache-efficient.
                            </p>
                            <p>
                                To evaluate our data structure, we implemented Parallel Packed Compressed Sparse Row
                                (PPCSR), a
                                dynamic-graph processing framework that extends the Ligra interface with graph updates.
                                We
                                show
                                that
                                PPCSR is on average about 1.6x faster on graph kernels than Aspen, a state-of-the-art
                                graph-streaming system. PPCSR achieves up to 80 million updates per second and is 2 – 5x
                                faster
                                than
                                Aspen on most batch sizes. Finally, PPCSR is competitive with Ligra and Ligra+, two
                                state-of-the-art
                                static graph-processing frameworks.
                            </p>
                        </details>
                        <br>
                        <ul class="text-left" style="display:inline-block;vertical-align:middle;padding-left:0">

                            <li>Presented at <a href="https://www.siam.org/conferences/cm/conference/alenex21">ALENEX
                                    2021</a></li>
                            <li>For a video of the talk, see <a href="https://youtu.be/LJ2B7w-UyLw">here</a></li>
                        </ul>
                    </ul>
                </div>
            </div>
        </section>

        <!-- Post Section -->
        <section id="post" class="container text-center">
            <div class="row filterDiv others">
                <hr>
                <div class="col-lg-12 col-lg-offset-0">
                    <h2><a href="https://ieeexplore.ieee.org/abstract/document/9286243">High-Throughput
                            Image Alignment for
                            Connectomics using Frugal Snap Judgments</a></h2>
                    <p><a href="http://tfk.mit.edu/">Tim Kaler</a>, <b>Brian Wheatman</b>, and <a
                            href="https://swooders.com/"> Sarah Wooders</a></p>
                    <ul class="text-left">
                        <details>
                            <summary>
                                <strong>Abstract</strong>
                            </summary>
                            <p>
                                The accuracy and computational efficiency of image alignment directly affects
                                the advancement of connectomics, a field which seeks to understand the
                                structure of the brain through electron microscopy.
                            </p>
                            <p>
                                We introduce the algorithms Quilter and Stacker that are designed to perform 2D
                                and 3D alignment respectively on petabyte-scale data sets from connectomics.
                                Quilter and Stacker are efficient, scalable, and simple to deploy on hardware
                                ranging from a researcher's laptop to a large computing cluster. On a single
                                18-core cloud machine each algorithm achieves throughputs of more than 1
                                TB/hr; when combined the algorithms produce an end-to-end alignment pipeline
                                that processes data at a rate of 0.82 TB/hr - an over 10x improvement
                                from previous systems. This efficiency comes from both traditional
                                optimizations and from the use of ``Frugal Snap Judgments'' to judiciously
                                exploit performance--accuracy trade offs.
                            </p>
                            <p>
                                A high-throughput image-alignment pipeline was implemented using the Quilter
                                and Stacker algorithms and its performance was evaluated using three datasets
                                whose size ranged from 550GB to 38TB. The full alignment pipeline achieved
                                a throughput of 0.6-0.8 TB/hr and 1.4-1.5 TB/hr on an 18-core and
                                112-core shared-memory multicore, respectively. On a supercomputing cluster
                                with 200 nodes and 1600 total cores, the pipeline achieved a throughput of
                                21.4 TB/hr.
                            </p>
                        </details>
                        <br>
                        <ul class="text-left" style="display:inline-block;vertical-align:middle;padding-left:0">
                            <li> Presented as a <a href="https://dl.acm.org/doi/abs/10.1145/3293883.3301495">Poster</a>
                                at PPOPP 2019.</li>
                            <li>Presented as a paper at <a href="http://www.ieee-hpec.org/">HPEC 2020</a>, where
                                it
                                won
                                the
                                best student paper award.</li>
                        </ul>

                    </ul>
                </div>
            </div>

        </section>

        <!-- Post Section -->
        <section id="post" class="container text-center">
            <div class="row filterDiv DS graphs">
                <hr>
                <div class="col-lg-12 col-lg-offset-0">
                    <h2><a href="https://ieeexplore.ieee.org/abstract/document/8547566">Packed
                            Compressed Sparse Row: A
                            Dynamic Graph Representation </a></h2>
                    <p><b>Brian Wheatman</b> and <a href="https://itshelenxu.github.io/">Helen Xu</a></p>
                    <ul class="text-left">
                        <details>
                            <summary>
                                <strong>Abstract</strong>
                            </summary>
                            <p>Perhaps the most popular sparse graph storage format is Compressed Sparse Row (CSR). CSR
                                excels
                                at
                                storing graphs compactly with minimal overhead, allowing for fast traversals, lookups,
                                and
                                basic
                                graph computations such as PageRank. Since elements in CSR format are packed together,
                                additions
                                and
                                deletions often require time linear in the size of the graph.
                            </p>
                            <p>
                                We introduce a new dynamic sparse
                                graph representation called Packed Compressed Sparse Row (PCSR), based on an array-based
                                dynamic
                                data structure called the Packed Memory Array. PCSR is similar to CSR, but leaves spaces
                                between
                                elements, allowing for asymptotically faster insertions and deletions in exchange for a
                                constant
                                factor slowdown in traversals and a constant factor increase in space overhead.
                            </p>
                            <p>
                                Our contributions
                                are twofold. We describe PCSR and review the theoretical guarantees for update, insert,
                                and
                                search
                                for PCSR. We also implemented PCSR as well as other basic graph storage formats and
                                report
                                our
                                findings on a variety of benchmarks. PCSR supports inserts orders of magnitude faster
                                than
                                CSR
                                and
                                is only a factor of two slower on graph traversals. Our results suggest that PCSR is a
                                lightweight
                                dynamic graph representation that supports fast inserts and competitive searches.
                            </p>
                        </details>
                        <br>
                        <ul class="text-left" style="display:inline-block;vertical-align:middle;padding-left:0">
                            <li>Presented at <a href="http://www.ieee-hpec.org/2018/">HPEC
                                    2018</a></li>
                        </ul>
                    </ul>

                </div>
            </div>
        </section>



        <!-- Post Section -->
        <section id="post" class="container text-center">
            <div class="row filterDiv others">
                <hr>
                <div class="col-lg-12 col-lg-offset-0">
                    <h2><a href="https://link.springer.com/chapter/10.1007/978-3-319-39931-7_19">Electricity
                            Demand and
                            Population Dynamics Prediction from Mobile Phone Metadata </a></h2>
                    <p><b>Brian Wheatman</b>, Alejandro Noriega and <a
                            href="https://www.media.mit.edu/people/sandy/overview/">Alex Pentland</a></p>
                    <ul class="text-left">
                        <details>
                            <summary>
                                <strong>Abstract</strong>
                            </summary>
                            <p>Energy efficiency is a key challenge for building modern sustainable societies. World’s
                                energy
                                consumption is expected to grow annually by 1.6 %, increasing pressure for utilities and
                                governments
                                to fulfill demand and raising significant challenges in generation, distribution, and
                                storage of
                                electricity. In this context, accurate predictions and understanding of population
                                dynamics
                                and
                                their relation to electricity demand dynamics is of high relevance.
                            </p>
                            <p>
                                We introduce a simple machine learning (ML) method for day-ahead predictions of hourly
                                energy
                                consumption, based on population and electricity demand dynamics. We use anonymized
                                mobile
                                phone
                                records (CDRs) and historical energy records from a small European country. CDRs are
                                large-scale
                                data that is collected passively and on a regular basis by mobile phone carriers,
                                including
                                time
                                and
                                location of calls and text messages, as well as phones’ countries of origin. We show
                                that
                                simple
                                support vector machine (SVM) autoregressive models are capable of baseline energy demand
                                predictions
                                with accuracies below 3 % percentage error and active population predictions below 10 %
                                percentage
                                error. Moreover, we show that population dynamics from mobile phone records contain
                                information
                                additional to that of electricity demand records, which can be exploited to improve
                                prediction
                                performance. Finally, we illustrate how the joint analysis of population and electricity
                                dynamics
                                elicits insights into the relation between population and electricity demand segments,
                                allowing
                                for
                                potential demand management interventions and policies beyond reactive supply-side
                                operations.
                            </p>
                        </details>
                        <br>
                        <ul class="text-left" style="display:inline-block;vertical-align:middle;padding-left:0">
                            <li>
                                Presented at <a href="http://sbp-brims.org/2016/">SBP-BRiMS 2016</a>
                            </li>
                        </ul>
                    </ul>
                </div>
            </div>
        </section>
    </section>

    <section id="Invited Talks" class="container content-section text-center">
        <h1><u>Invited Talks</u></h1>

        <section id="post" class="container text-center">
            <div class="row ">
                <hr>
                <div class="col-lg-12 col-lg-offset-0">
                    <h2>Recent Improvements to Packed Memory Arrays</h2>
                    <p><b>Brian Wheatman</b></p>
                    <ul class="text-left">
                        <details>
                            <summary>
                                <strong>Abstract</strong>
                            </summary>
                            <p>
                                A Packed Memory Array (PMA) is a dynamic data structure that stores N elements in O(N) space.  It supports reasonably efficient updates (inserts and deletes) and extremely efficient scans.  However, traditional PMAs are theoretically (and often empirically) dominated by B-Trees in many situations.  This talk will present recent advancements that enable PMAs to surpass B-Trees in various scenarios, positioning them as a superior choice for ordered sets.
                            </p>
                            <p>
                                First, we will discuss optimizations to searching in a PMA, showing how PMAs can asymptotically match and empirically outperform B-Trees.  Then we will review improvements to updating a PMA with improvements in serial insert as well as a new parallel batch insert algorithm for PMAs. Lastly, we will explore techniques that reduce the space usage for PMAs, which both decrease the memory usage and increase the throughput of many operations due to the decreased memory bandwidth. 
                            </p>
                        </details>
                        <br>
                        <ul class="text-left" style="display:inline-block;vertical-align:middle;padding-left:0">

                            <li>Invited talk at <a href="https://sites.gatech.edu/spaa24datastr/">Workshop on Recent Advances in Parallel and Concurrent Data Structures</a> at SPAA 2024
                            </li> 
                            <li>For a video of the talk, see <a href="https://www.youtube.com/watch?v=SHOqZYVvEvY">here</a></li>

                        </ul>
                    </ul>
                </div>
            </div>

        </section>

        <section id="post" class="container text-center">
            <div class="row ">
                <hr>
                <div class="col-lg-12 col-lg-offset-0">
                    <h2>Ordered Sets: An Evolution of Memory Optimized Data Structures</h2>
                    <p><b>Brian Wheatman</b></p>
                    <ul class="text-left">
                        <details>
                            <summary>
                                <strong>Abstract</strong>
                            </summary>
                            <p>
                                Ordered sets are a fundamental building block used all over computer science.  We will review the different approaches used to implement ordered sets over the years with a focus on practical performance.  Then we will turn to Packed Memory Arrays, evaluate their strengths and weaknesses.  My research overcomes these limitations in search and insert performance and allows the packed memory array to outperform other approaches on modern highly parallel architectures.
                            </p>

                        </details>
                        <br>
                        <ul class="text-left" style="display:inline-block;vertical-align:middle;padding-left:0">

                            <li>Invited <a href = "http://cs-www.uchicago.edu/events/event/brian-wheatman-john-hopkins-ordered-sets-an-evolution-of-memory-optimized-data-structures/">talk</a> at University of Chicago 
                            </li>

                        </ul>
                    </ul>
                </div>
            </div>
        </section>

        <section id="post" class="container text-center">
            <div class="row ">
                <hr>
                <div class="col-lg-12 col-lg-offset-0">
                    <h2>So You Want to Make a Dynamic Graph Data Structure</h2>
                    <p><b>Brian Wheatman</b></p>
                    <ul class="text-left">
                        <details>
                            <summary>
                                <strong>Abstract</strong>
                            </summary>
                            <p>
                                This talk discusses dynamic graph data structures and what to consider when designing
                                new ones. It breaks the task of designing graph data structures into creating structures
                                that can support a few key operations efficiently. The focus is on how different use
                                cases, which can cause different data patterns and access patterns, can influence the
                                design of these structures and how to exploit these differences to maximize performance.
                            </p>

                        </details>
                        <br>
                        <ul class="text-left" style="display:inline-block;vertical-align:middle;padding-left:0">

                            <li>Invited talk at <a href="https://paralg.github.io/largescalegraphs/">Workshop
                                    on Large-Scale Graph Processing</a> as SPAA 2022
                            </li>

                        </ul>
                    </ul>
                </div>
            </div>
        </section>


    </section>

    <section id="Current" class="container content-section text-center">
        <hr>
        <h1><u>Current Work</u></h1>


        <section id="post" class="container text-center">
            <div class="row">
                <div class="col-lg-12 col-lg-offset-0">
                    <h2><a href="https://arxiv.org/abs/2402.14118">Masked Matrix Multiplication for Emergent
                            Sparsity</a></h2>
                    <ul class="text-left">
                        <details>
                            <summary>
                                <strong>Abstract</strong>
                            </summary>
                            <p>
                                Artificial intelligence workloads, especially transformer models, exhibit emergent
                                sparsity
                                in which computations perform selective sparse access to dense data. The workloads are
                                inefficient on hardware designed for dense computations and do not map well onto sparse
                                data
                                representations. We build a vectorized and parallel matrix-multiplication system A × B =
                                C
                                that eliminates unnecessary computations and avoids branches based on a runtime
                                evaluation
                                of sparsity. We use a combination of dynamic code lookup to adapt to the specific
                                sparsity
                                encoded in the B matrix and preprocessing of sparsity maps of the A and B matrices to
                                compute conditional branches once for the whole computation. For a wide range of
                                sparsity,
                                from 60% to 95% zeros, our implementation performs fewer instructions and increases
                                performance when compared with Intel MKL's dense or sparse matrix multiply routines.
                                Benefits can be as large as 2 times speedup and 4 times fewer instructions.
                            </p>
                        </details>
                    </ul>

                </div>
            </div>
            <hr>
        </section>


        <section id="post" class="container text-center">
            <div class="row">
                <div class="col-lg-12 col-lg-offset-0">
                    <h2>General Purpose, Memory-Efficient Data Structures</h2>
                    <ul class="text-left">
                        <details>
                            <summary>
                                <strong>Abstract</strong>
                            </summary>
                            <p>
                                My vision is to create a suite of data structures, which implement memory-efficient
                                versions
                                of common operations, so users can reap these benefits across many problems and scales
                                without needing the technical expertise to understand and tune for the memory hierarchy.

                                The next steps are to continue to develop techniques for adapting structures dynamically
                                to
                                best suit the data pattern and problem structure, as well as move from dynamic graphs to
                                more general structures, such as sets and matrices. Some specific examples are as
                                follows:
                            </p>
                            <p>
                                A graph library for storing the time history of a graph, where instead of being able to
                                update a
                                graph to store the current version in respect to changes over time, would instead store
                                the
                                complete history of the graph, so that any point in time can be efficiently queried.
                                Furthermore, multiple different points in time will be able to be analyzed at the same
                                time,
                                sharing work and I/O between the different queries.
                            </p>
                            <p>
                                A Dynamic Sparse Matrix Library called Concord, which will
                                build off of the SSTGraph and adapt to efficiently store matrices of many different
                                forms
                                and enable both standard computation with separate output and inplace updates. Concord
                                will
                                take advantage of its dynamic structure, without having to perform rewrites or
                                pre-calculate
                                the matrix’s pattern. </p>
                        </details>
                    </ul>


                </div>
            </div>
            <hr>
        </section>





    </section>


    <!-- Education Section -->
    <section id="education" class="container content-section text-center">
        <h2>Education</h2>
        <ul class="text-left" style="display:inline-block;vertical-align:middle;">
            <p>I am currently a PhD Student in Computer Science at Johns Hopkins
                University advised by <a href="https://www.cs.jhu.edu/faculty/randal-burns/">Randal
                    Burns</a>. I received the Gordon
                Croft Fellowship.
            </p>
            <p>I earned my Masters of Engineering from Massachusetts Institute of
                Technology (MIT) in 2019,
                working
                with <a href="https://www.csail.mit.edu/person/charles-e-leiserson">
                    Charles E. Leiserson</a>.

            </p>

            <p>I earned my Bachelors of Science from Massachusetts Institute of
                Technology in 2017, completing a
                double major in Computer Science and Mathematics and a double minor in
                Economics and Management
                Science. I am a member of both the Engineering Honor Society (TBP) and
                the Computer Science
                Honor
                Society (HKN). I was the Lockheed Martin Undergraduate Research and
                Innovation Scholar, under
                the
                supervision of <a href="https://www.csail.mit.edu/person/daniela-rus">Daniela
                    Rus</a> and <a href="https://aeroastro.mit.edu/sertac-karaman">Sertac
                    Karaman</a>.</p>
            <hr>
            <p>Master's Thesis:</p>
            <h4><a href="https://dspace.mit.edu/handle/1721.1/123023">Image
                    alignment and dynamic graph analytics : two case studies of how managing data movement
                    can make (parallel) code run fast</a></h4>
            <ul class="text-left">
                <details>
                    <summary>
                        <strong>Abstract</strong>
                    </summary>
                    High performance applications are becoming increasingly resource hungry. We want to
                    solve more complex problems and use more data to get higher quality results. However,
                    the more data we store, the slower it is to access any piece. This effect is seen
                    directly in the memory hierarchy. We can access our caches faster than our memory, which
                    is faster than reading our disk, which is still faster than going across the network.
                    This means that when processing large data sets, we can spend a large portion of our
                    time simply in data movement. However, there is much we can do to optimize our programs
                    to exploit our memory systems, so that we do not incur performance degradation as our
                    datasets grow. I show how the careful design of data structures and algorithms allow us
                    to scale to much larger datasets without impacting performance due to the cost of data
                    movement. I demonstrate the impact of these designs with two case studies. The first
                    examines large-scale image alignment, where I describe how to align a petabyte scale set
                    of images in memory on a single machine and match the performance of current cluster
                    solutions. I achieve .6 - .8 TB/hr on a medium-sized multicore and linear scalability on
                    hundreds of nodes in a shared supercomputing cluster. The second case study explores
                    dynamic graph analytics, where I describe the design of a new data structure for storing
                    dynamic graphs that matches the performance of standard, static formats and enables high
                    performance, dynamic operations achieving millions of updates per second.
                    </p>
                </details>

            </ul>
            <hr>
            <p>For my undergraduate senior seminar paper in Discrete Math, I studied Anti-magic graphs.</p>
            <h4><a href="https://brianwheatman.com/papers/Anti_magic.pdf">Anti-magic
                    and Edge Graceful Graphs</a>
            </h4>

            <hr>

            <p>For my undergraduate senior research paper in Computer Science, I studied a variant of the Traveling
                Salesman
                Problem.</p>
            <h4><a href="https://brianwheatman.com/papers/Tourist_Path_Optimization_Problem.pdf">Tourist
                    Path
                    Optimization
                    Problem</a></h4>


        </ul>
    </section>

    <!-- Teaching Section -->
    <section id="teaching" class="container content-section text-center">
        <h2>Teaching</h2>
        <ul class="text-left" style="display:inline-block;vertical-align:middle;">


            <p>I have worked with a variety of classes from my undergrad through my PhD:
            </p>
            <ul class="text-left" style="display:inline-block;vertical-align:middle;">
                <li>Guest Lecture: <a href="https://github.com/wheatman/Vectorization_Notes">SIMD and
                        Vectorization</a> for HPC Tools and Applications (Georgia Tech <a
                        href="https://sites.gatech.edu/cse6230spring24/">CSE 6230</a>):
                    Spring 2024 (<a href = "https://www.youtube.com/watch?v=hSzYRgc5PYY&ab_channel=GTCSEHPCCourseVideos">video</a>)</li>
                <li>Parallel Programming (JHU <a href="https://parallel.cs.jhu.edu/">CS320/620</a>):
                    Teaching
                    Assistant (TA) Fall 2023, Fall 2021, Course Assistant Fall 2022</li>
                <li>Guest Lecture: <a href="https://github.com/wheatman/Vectorization_Notes">SIMD and
                        Vectorization</a> for Scalable Parallel Algorithms and Data Structures at University of Maryland (UMD <a
                        href="https://www.cs.umd.edu/~laxman/paralg-s23.html">CMSC858N</a>):
                    Spring 2023</li>
                <li>Intermediate Programming (JHU <a href="http://www.dsn.jhu.edu/courses/cs220/">CS220</a>):
                    TA Fall 2020</li>
                <li>Computation Structures (MIT <a href="https://6004.mit.edu">
                        6.004</a>): Head TA
                    Spring
                    2019, TA Spring 2018, Fall 2018</li>
                <li>Advanced Undergraduate Research (MIT <a href="https://superurop.mit.edu/">
                        6.UAR</a>):
                    TA
                    Fall
                    2017
                </li>
                <li>Digital Communication Systems (MIT <a href="https://visor.mit.edu/6.02/f2020">6.02</a>):
                    Lab
                    Assistant Fall 2016</li>
                <li>Algorithms (MIT 6.006 and 6.046): Tutoring and Grading 2015-2016
                </li>
            </ul>

        </ul>
    </section>


    <!-- Service Section -->
    <section id="Service" class="container content-section text-center">
        <h2>Service</h2>
        <ul class="text-left" style="display:inline-block;vertical-align:middle;">

            <p>I organize and run a reading group for the PhD students in the systems groups at JHU.</p>
            <p>I contribute to the <a href="https://www.opencilk.org/">OpenCilk</a> parallel programming
                platform. </p>

            <p>Committees served on </p>
            <ul class="text-left" style="display:inline-block;vertical-align:middle;">
                <li>Highlights of Parallel Computing (HOPC 2024) Program Committee </li>
                <li>ACM SIGPLAN Principles and Practice of Parallel Programming (PPoPP 2024)
                    Artifact
                    Evalutation Committee</li>
            </ul>
            <br><br>
            <p>External Reviewer</p>
            <ul class="text-left" style="display:inline-block;vertical-align:middle;">
                <li>European Symposium on Algorithms (ESA 2023)</li>
                <li>Symposium on Experimental Algorithms (SEA 2023, 2022)</li>
                <li>ACM Symposium on Parallelism in Algorithms and Architectures (SPAA 2023, 2022)</li>
                <li>SIAM Journal on Computing (SICOMP 2023)</li>
                <li>IEEE International Parallel & Distributed Processing Symposium (IPDPS 2023)</li>
                <li>SIAM Symposium on Algorithm Engineering and Experiments (ALENEX23)</li>
                <li>IEEE International Conference on BigData (BigData 2022)</li>
                <li>IEEE Symposium on Foundations of Computer Science (FOCS 2022)</li>
                <li>SIAM Conference on Applied and Computational Discrete Algorithms (ACDA 2021)</li>

            </ul>

        </ul>
    </section>

    <!-- Profession Experience  Section -->
    <section id="professional" class="container content-section text-center">
        <h2>Professional Experience</h2>
        <ul class="text-left" style="display:inline-block;vertical-align:middle;">
            <p>I have completed multiple Software and Data Engineering internships:</p>
            <ul class="text-left" style="display:inline-block;vertical-align:middle;">
                <li> Lawrence Berkeley National Laboratory: Summer 2022</li>
                <li> Google: Summers 2017, 2018, 2019, 2020, 2021, 2023</li>
                <li> Five Rings Capital: Winter 2017</li>
                <li> Facebook: Summer 2016</li>
                <li> JP Morgan Chase & Co. Summer 2015</li>
            </ul>
        </ul>
    </section>


    <!-- CV Section -->
    <section id="CV" class="content-section text-center">
        <div class="resume-section">
            <div class="container">
                <div class="col-lg-12 col-lg-offset-0">
                    <h2>View My CV</h2>
                    <ul class="text-left" style="display:inline-block;vertical-align:middle;">
                        <p>You can see my academic and professional experiences via the linked
                            CV.</p>
                    </ul>
                    <br>
                    <a href="cv.pdf" class="btn btn-default btn-lg">CV</a>

                </div>
            </div>
        </div>
    </section>

    <!-- Footer -->
    <footer>
        <div class="container text-center">
            <p>Copyright &copy; Brian Wheatman 2024</p>
        </div>
    </footer>

    <!-- jQuery -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.7.0/jquery.min.js"></script>

    <!-- Bootstrap Core JavaScript -->
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/js/bootstrap.min.js"
        integrity="sha384-0mSbJDEHialfmuBBQP6A4Qrprq5OVfW37PRR3j5ELqxss1yVqOtnepnHVP9aJ7xS"
        crossorigin="anonymous"></script>

    <!-- Plugin JavaScript -->
    <script src="js/jquery.easing.min.js"></script>

    <!-- Custom Theme JavaScript -->
    <script src="js/grayscale.js"></script>
    <script>
        filterSelection("all");

        function filterSelection(c) {
            var x, i;
            x = document.getElementsByClassName("filterDiv");
            if (c == "all") c = "";
            for (i = 0; i < x.length; i++) {
                RemoveClass(x[i], "fshow");
                if (x[i].className.indexOf(c) > -1) AddClass(x[i], "fshow");
            }
        }

        function AddClass(element, name) {
            var i, arr1, arr2;
            arr1 = element.className.split(" ");
            arr2 = name.split(" ");
            for (i = 0; i < arr2.length; i++) {
                if (arr1.indexOf(arr2[i]) == -1) { element.className += " " + arr2[i]; }
            }
        }

        function RemoveClass(element, name) {
            var i, arr1, arr2;
            arr1 = element.className.split(" ");
            arr2 = name.split(" ");
            for (i = 0; i < arr2.length; i++) {
                while (arr1.indexOf(arr2[i]) > -1) {
                    arr1.splice(arr1.indexOf(arr2[i]), 1);
                }
            }
            element.className = arr1.join(" ");
        }

        // Add active class to the current button (highlight it)
        var btnContainer = document.getElementById("myBtnContainer");
        var btns = btnContainer.getElementsByClassName("fbtn");
        for (var i = 0; i < btns.length; i++) {
            btns[i].addEventListener("click", function () {
                var current = document.getElementsByClassName("clicked");
                current[0].className = current[0].className.replace("clicked", "");
                this.className += " clicked";
            });
        }
    </script>
</body>

</html>
